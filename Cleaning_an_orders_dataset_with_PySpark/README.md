# Cleaning_an_orders_dataset_with_PySpark

This project demonstrates how to load, transform, and analyze large datasets using Apache Spark and Pandas. The primary focus is on reading Parquet files, converting data between Spark and Pandas, and previewing the data for further analysis.

This project showcases the process of handling and exploring data efficiently using a combination of Spark and Pandas. It serves as an example for data engineers and data scientists working with large datasets stored in Parquet format.

**Features**
1. Load data from Parquet files using Apache Spark.
2. Convert Spark DataFrames to Pandas DataFrames for ease of use.
3. Perform basic data exploration and preview datasets.

***To start the project, you need to download one of the versions of Jupyter Notebook and download 1 attached dataset. All necessary connections are inside***
-----------------------------
